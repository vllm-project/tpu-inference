# meta-llama/Llama-3.1-8B-Instruct
steps:
  - label: "Unit tests for meta-llama/Llama-3.1-8B-Instruct"
    key: "meta-llama_Llama-3_1-8B-Instruct_UnitTest"
    soft_fail: true
    agents:
      queue: tpu_v6e_queue
    commands:
      - |
        .buildkite/scripts/run_in_docker.sh \
          bash -c 'python3 -m pytest -s -v -x /workspace/tpu_inference/tests/models/jax/test_llama3.py'
  - label: "Record unit test result for meta-llama/Llama-3.1-8B-Instruct"
    key: "record_meta-llama_Llama-3_1-8B-Instruct_UnitTest"
    depends_on: "meta-llama_Llama-3_1-8B-Instruct_UnitTest"
    env:
      CI_STAGE: "UnitTest"
      CI_TARGET: meta-llama/Llama-3.1-8B-Instruct
    agents:
      queue: tpu_v6e_queue
    commands:
      - |
        .buildkite/scripts/record_step_result.sh meta-llama_Llama-3_1-8B-Instruct_UnitTest

  - label: "Integration tests for meta-llama/Llama-3.1-8B-Instruct"
    key: "meta-llama_Llama-3_1-8B-Instruct_IntegrationTest"
    depends_on: "record_meta-llama_Llama-3_1-8B-Instruct_UnitTest"
    agents:
      queue: tpu_v6e_queue
    soft_fail: true
    env:
      TEST_MODEL: meta-llama/Llama-3.1-8B-Instruct
      TENSOR_PARALLEL_SIZE: 1
      MINIMUM_ACCURACY_THRESHOLD: 0.75
    commands:
      - |
        .buildkite/scripts/run_in_docker.sh bash /workspace/tpu_inference/tests/e2e/benchmarking/test_accuracy.sh
  - label: "Record integration test result for meta-llama/Llama-3.1-8B-Instruct"
    key: "record_meta-llama_Llama-3_1-8B-Instruct_IntegrationTest"
    depends_on: "meta-llama_Llama-3_1-8B-Instruct_IntegrationTest"
    env:
      CI_TARGET: meta-llama/Llama-3.1-8B-Instruct
      CI_STAGE: "IntegrationTest"
    agents:
      queue: tpu_v6e_queue
    commands:
      - |
        .buildkite/scripts/record_step_result.sh meta-llama_Llama-3_1-8B-Instruct_IntegrationTest

  - label: "Performance benchmarks for meta-llama/Llama-3.1-8B-Instruct"
    key: "meta-llama_Llama-3_1-8B-Instruct_Benchmark"
    depends_on: "record_meta-llama_Llama-3_1-8B-Instruct_IntegrationTest"
    soft_fail: true
    agents:
      queue: tpu_v6e_queue
    env:
      TEST_MODEL: meta-llama/Llama-3.1-8B-Instruct
      TENSOR_PARALLEL_SIZE: 1
      MINIMUM_THROUGHPUT_THRESHOLD: 10.77
      INPUT_LEN: 1800
      OUTPUT_LEN: 128
      PREFIX_LEN: 0
      MAX_MODEL_LEN: 2048
      MAX_NUM_SEQS: 256
      MAX_NUM_BATCHED_TOKENS: 1024
    commands:
      - |
        .buildkite/scripts/run_in_docker.sh bash /workspace/tpu_inference/tests/e2e/benchmarking/benchmark.sh
  - label: "Record performance benchmark result for meta-llama/Llama-3.1-8B-Instruct"
    key: "record_meta-llama_Llama-3_1-8B-Instruct_Benchmark"
    depends_on: "meta-llama_Llama-3_1-8B-Instruct_Benchmark"
    env:
      CI_TARGET: meta-llama/Llama-3.1-8B-Instruct
      CI_STAGE: "Benchmark"
    agents:
      queue: tpu_v6e_queue
    commands:
      - |
        .buildkite/scripts/record_step_result.sh meta-llama_Llama-3_1-8B-Instruct_Benchmark
