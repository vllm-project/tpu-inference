# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

steps:
  - group: "${TESTS_GROUP_LABEL:-[jax] TPU6e Tests Group}"
    steps:
      # -----------------------------------------------------------------
      # TEST STEPS - Calling wrapper
      # -----------------------------------------------------------------
      - label: "${TPU_VERSION:-tpu6e} E2E MLPerf tests for JAX models"
        key: "${TPU_VERSION:-tpu6e}_test_0"
        soft_fail: true
        env:
          IS_FOR_V7X: "${IS_FOR_V7X}"
        agents:
          queue: ${TPU_QUEUE_SINGLE:-tpu_v6e_queue}
        commands:
          - .buildkite/scripts/run_in_docker.sh bash /workspace/tpu_inference/tests/e2e/benchmarking/mlperf.sh

      - label: "${TPU_VERSION:-tpu6e} E2E MLPerf tests for JAX models with quantization"
        key: ${TPU_VERSION:-tpu6e}_test_1
        soft_fail: true
        env:
          QUANTIZATION: "True"
          IS_FOR_V7X: "${IS_FOR_V7X}"
        agents:
          queue: ${TPU_QUEUE_SINGLE:-tpu_v6e_queue}
        if: build.env("NIGHTLY") == "1"
        commands:
          - .buildkite/scripts/run_in_docker.sh bash /workspace/tpu_inference/tests/e2e/benchmarking/mlperf.sh

      - label: "${TPU_VERSION:-tpu6e} E2E MLPerf tests for JAX new models"
        key: ${TPU_VERSION:-tpu6e}_test_2
        soft_fail: true
        env:
          NEW_MODEL_DESIGN: "1"
          IS_FOR_V7X: "${IS_FOR_V7X}"
        agents:
          queue: ${TPU_QUEUE_SINGLE:-tpu_v6e_queue}
        if: build.env("NIGHTLY") == "1"
        commands:
          - .buildkite/scripts/run_in_docker.sh bash /workspace/tpu_inference/tests/e2e/benchmarking/mlperf.sh

      - label: "${TPU_VERSION:-tpu6e} E2E MLPerf tests for JAX + vLLM models on single chip"
        key: ${TPU_VERSION:-tpu6e}_test_3
        soft_fail: true
        env:
          MODEL_IMPL_TYPE: "vllm"
          IS_FOR_V7X: "${IS_FOR_V7X}"
        agents:
          queue: ${TPU_QUEUE_SINGLE:-tpu_v6e_queue}
        commands:
          - .buildkite/scripts/run_in_docker.sh bash /workspace/tpu_inference/tests/e2e/benchmarking/mlperf.sh

      - label: "${TPU_VERSION:-tpu6e} E2E MLperf tests for Llama4 models"
        key: ${TPU_VERSION:-tpu6e}_test_4
        soft_fail: true
        env:
          NEW_MODEL_DESIGN: "1"
          USE_V6E8_QUEUE: "True"
          IS_FOR_V7X: "${IS_FOR_V7X}"
        agents:
          queue: ${TPU_QUEUE_MULTI:-tpu_v6e_8_queue}
        if: build.env("NIGHTLY") == "1"
        commands:
          - .buildkite/scripts/run_in_docker.sh bash /workspace/tpu_inference/tests/e2e/benchmarking/mlperf.sh

      - label: "${TPU_VERSION:-tpu6e} E2E speculative decoding test"
        key: ${TPU_VERSION:-tpu6e}_test_6
        soft_fail: true
        env:
          IS_FOR_V7X: "${IS_FOR_V7X}"
        agents:
          queue: ${TPU_QUEUE_SINGLE:-tpu_v6e_queue}
        commands:
          - |
              .buildkite/scripts/run_in_docker.sh \
                bash -c 'python3 -m pytest -s -v -x /workspace/tpu_inference/tests/e2e/test_speculative_decoding.py'
                
      - label: "${LABEL_PREFIX}JAX unit tests part1"
        key: ${KEY_PREFIX}test_7_1
        soft_fail: true
        env:
          IS_FOR_V7X: "${IS_FOR_V7X}"
        artifact_paths: ".coverage.part1.${KEY_PREFIX}"
        agents:
          queue: ${TPU_QUEUE_SINGLE:-tpu_v6e_queue}
        commands:
          - |
            .buildkite/scripts/run_in_docker.sh bash -c "python3 -m pytest -s -v -x /workspace/tpu_inference/tests/layers/jax --ignore=/workspace/tpu_inference/tests/kernels --ignore=/workspace/tpu_inference/tests/lora --ignore=/workspace/tpu_inference/tests/e2e --ignore=/workspace/tpu_inference/tpu_inference/mock --ignore=/workspace/tpu_inference/tests/layers/vllm/test_compressed_tensors_moe.py --ignore=/workspace/tpu_inference/tests/models/jax/test_deepseek_v3.py --cov-config=/workspace/tpu_inference/.coveragerc --cov tpu_inference; if [ -f .coverage ]; then cp .coverage /tmp/hf_home/.coverage.part1.${KEY_PREFIX}; fi"         
          - cp /mnt/disks/persist/models/.coverage.part1.${KEY_PREFIX} ./
             
      - label: "${LABEL_PREFIX}JAX unit tests part2"
        key: ${KEY_PREFIX}test_7_2
        soft_fail: true
        env:
          IS_FOR_V7X: "${IS_FOR_V7X}"
        artifact_paths: ".coverage.part2.${KEY_PREFIX}"
        agents:
          queue: ${TPU_QUEUE_SINGLE:-tpu_v6e_queue}
        commands:
          - |
            .buildkite/scripts/run_in_docker.sh bash -c "python3 -m pytest -s -v -x /workspace/tpu_inference/tests/ --ignore=/workspace/tpu_inference/tests/layers/jax --ignore=/workspace/tpu_inference/tests/kernels --ignore=/workspace/tpu_inference/tests/lora --ignore=/workspace/tpu_inference/tests/e2e --ignore=/workspace/tpu_inference/tpu_inference/mock --ignore=/workspace/tpu_inference/tests/models/jax/test_deepseek_v3.py --cov-config=/workspace/tpu_inference/.coveragerc --cov tpu_inference; if [ -f .coverage ]; then cp .coverage /tmp/hf_home/.coverage.part2.${KEY_PREFIX}; fi"
          - cp /mnt/disks/persist/models/.coverage.part2.${KEY_PREFIX} ./
           
      - label: "${LABEL_PREFIX}JAX unit tests combine and report"
        depends_on: 
          - "${KEY_PREFIX}test_7_1"
          - "${KEY_PREFIX}test_7_2"
        key: "${KEY_PREFIX}test_7_3"
        soft_fail: true
        env:
          IS_FOR_V7X: "${IS_FOR_V7X}"
        agents:
          queue: cpu
        commands:
          - "buildkite-agent artifact download \".coverage.part*\" ."
          - curl -L https://github.com/pantsbuild/pex/releases/download/v2.1.151/pex -o pex
          - chmod +x pex
          - python3 ./pex coverage -c coverage -o coverage.pex
          - |
            echo "[paths]" > .coveragerc
            echo "source =" >> .coveragerc
            echo "    ." >> .coveragerc
            echo "    /workspace/tpu_inference/" >> .coveragerc
          - "python3 ./coverage.pex combine .coverage.part1.${KEY_PREFIX} .coverage.part2.${KEY_PREFIX}"
          - "python3 ./coverage.pex report --fail-under=69"
           
      - label: "${TPU_VERSION:-tpu6e} JAX unit tests - kernels"
        key: ${TPU_VERSION:-tpu6e}_test_8
        soft_fail: true
        env:
          IS_FOR_V7X: "${IS_FOR_V7X}"
        agents:
          queue: ${TPU_QUEUE_SINGLE:-tpu_v6e_queue}
        commands:
          - |
            if [[ "$$NIGHTLY" == "1" ]] || git diff --name-only HEAD~1 | grep -qE '^(tpu_inference/kernels|tests/kernels|requirements.txt)'; then
              .buildkite/scripts/run_in_docker.sh \
                python3 -m pytest -s -v -x /workspace/tpu_inference/tests/kernels \
                --ignore=/workspace/tpu_inference/tests/kernels/ragged_paged_attention_kernel_v2_test.py \
                --ignore=/workspace/tpu_inference/tests/kernels/ragged_kv_cache_update_v2_test.py \
                --ignore=/workspace/tpu_inference/tests/kernels/collectives
            else
              echo "Skipping: Step requires either a NIGHTLY build or changes in kernels, kernel tests, or requirements.txt."
              exit 0
            fi

      - label: "${TPU_VERSION:-tpu6e} JAX unit tests - collective kernels"
        key: ${TPU_VERSION:-tpu6e}_test_9
        soft_fail: true
        env:
          IS_FOR_V7X: "${IS_FOR_V7X}"
        agents:
          queue: ${TPU_QUEUE_MULTI:-tpu_v6e_8_queue}
        commands:
          - |
            if [[ "$$NIGHTLY" == "1" ]] || git diff --name-only HEAD~1 | grep -qE '^(tpu_inference/kernels/collectives|tests/kernels/collectives|requirements.txt)'; then
              .buildkite/scripts/run_in_docker.sh \
                python3 -m pytest -s -v -x /workspace/tpu_inference/tests/kernels/collectives
            else
              echo "Skipping: Step requires either a NIGHTLY build or changes in kernels/collectives, tests, or requirements.txt."
              exit 0
            fi

      - label: "${TPU_VERSION:-tpu6e} lora e2e tests for JAX + vLLM models single chip"
        key: ${TPU_VERSION:-tpu6e}_test_10
        soft_fail: true
        env:
          IS_FOR_V7X: "${IS_FOR_V7X}"
        agents:
          queue: ${TPU_QUEUE_SINGLE:-tpu_v6e_queue}
        if: build.env("NIGHTLY") == "1"
        commands:
          - .buildkite/scripts/run_in_docker.sh bash -c 'MODEL_IMPL_TYPE=vllm TPU_BACKEND_TYPE=jax python3 -m pytest -s -v -x /workspace/tpu_inference/tests/lora/test_lora.py'

      - label: "${TPU_VERSION:-tpu6e} E2E MLPerf tests for JAX + vLLM models on multiple chips"
        key: ${TPU_VERSION:-tpu6e}_test_11
        soft_fail: true
        env:
          MODEL_IMPL_TYPE: "vllm"
          IS_FOR_V7X: "${IS_FOR_V7X}"
        agents:
          queue: ${TPU_QUEUE_MULTI:-tpu_v6e_8_queue}
        if: build.env("NIGHTLY") == "1"
        commands:
          - .buildkite/scripts/run_in_docker.sh bash /workspace/tpu_inference/tests/e2e/benchmarking/mlperf.sh

      # TODO (jacobplatin): re-enable this after b/467105149 is fixed
      - label: "${TPU_VERSION:-tpu6e} E2E MLperf tests for DeepSeek-R1 (no accuracy, 12-decoder layers only)"
        key: ${TPU_VERSION:-tpu6e}_test_12
        soft_fail: true
        env:
          NEW_MODEL_DESIGN: "1"
          USE_V6E8_QUEUE: "True"
          SKIP_ACCURACY_TESTS: "True"
          VLLM_MLA_DISABLE: "1"
          IS_FOR_V7X: "${IS_FOR_V7X}"
        agents:
          queue: ${TPU_QUEUE_MULTI:-tpu_v6e_8_queue}
        if: build.env("NIGHTLY") == "1" && build.env("IS_FOR_V7X") == "true"
        commands:
          - .buildkite/scripts/run_in_docker.sh bash /workspace/tpu_inference/tests/e2e/benchmarking/mlperf.sh -m jrplatin/DeepSeek-R1-1D-Subchannel-256  --use-dummy-weights

      - label: "${TPU_VERSION:-tpu6e} lora e2e tests for JAX + vLLM models multi chips"
        key: ${TPU_VERSION:-tpu6e}_test_13
        soft_fail: true
        env:
          TEST_LORA_TP: "True"
          VLLM_LOG_LEVEL: "INFO"
          IS_FOR_V7X: "${IS_FOR_V7X}"
        agents:
          queue: ${TPU_QUEUE_MULTI:-tpu_v6e_8_queue}
        if: build.env("NIGHTLY") == "1"
        commands:
          - .buildkite/scripts/run_in_docker.sh bash -c 'MODEL_IMPL_TYPE=vllm TPU_BACKEND_TYPE=jax python3 -m pytest -s -v -x /workspace/tpu_inference/tests/lora/test_lora.py'

      - label: "${TPU_VERSION:-tpu6e} lora unit tests on single chip"
        key: ${TPU_VERSION:-tpu6e}_test_15
        soft_fail: true
        env:
          IS_FOR_V7X: "${IS_FOR_V7X}"
        agents:
          queue: ${TPU_QUEUE_SINGLE:-tpu_v6e_queue}
        commands:
          - |
            .buildkite/scripts/run_in_docker.sh \
              bash -c ' python3 -m pytest -s -v -x /workspace/tpu_inference/tests/lora/test_bgmv.py && \
              python3 -m pytest -s -v -x /workspace/tpu_inference/tests/lora/test_layers.py'

      - label: "${TPU_VERSION:-tpu6e} lora unit tests on multi chips"
        key: ${TPU_VERSION:-tpu6e}_test_16
        soft_fail: true
        env:
          USE_V6E8_QUEUE: "True"
          VLLM_LOG_LEVEL: "INFO"
          IS_FOR_V7X: "${IS_FOR_V7X}"
        agents:
          queue: ${TPU_QUEUE_MULTI:-tpu_v6e_8_queue}
        commands:
          - .buildkite/scripts/run_in_docker.sh bash -c 'python3 -m pytest -s -v -x /workspace/tpu_inference/tests/lora/test_layers.py'

      - label: "${TPU_VERSION:-tpu6e} E2E lm_eval accuracy check qwen3 coder with fused moe."
        key: ${TPU_VERSION:-tpu6e}_test_17
        soft_fail: true
        env:
          IS_FOR_V7X: "${IS_FOR_V7X}"
        agents:
          queue: ${TPU_QUEUE_MULTI:-tpu_v6e_8_queue}
        commands:
          - |
            if [[ "$$IS_FOR_V7X" == "true" ]] && { [[ "$$NIGHTLY" == "1" ]] || git diff --name-only HEAD~1 | grep -qE '^(tpu_inference/kernels|tests/kernels|requirements(_.*)?\.txt)'; }; then
              .buildkite/scripts/run_in_docker.sh bash /workspace/tpu_inference/tests/e2e/check_lm_eval.sh  --model_name "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8" --use_moe_ep_kernel 1 --tensor_parallel_size 8 --max_model_len 2048 --max_num_batched_tokens 2048 --max_gen_toks 256 --enable_expert_parallel 1 --flex_threshold 0.85 --strict_threshold 0.70
            else
              echo "Skipping: Step requires TPU v7x and either a NIGHTLY build or kernel/requirements changes."
              exit 0
            fi

      - label: "${TPU_VERSION:-tpu6e} E2E lm_eval accuracy check qwen3 coder with gmm kernel."
        key: ${TPU_VERSION:-tpu6e}_test_18
        soft_fail: true
        env:
          IS_FOR_V7X: "${IS_FOR_V7X}"
        agents:
          queue: ${TPU_QUEUE_MULTI:-tpu_v6e_8_queue}
        commands:
          - |
            if [[ "$$IS_FOR_V7X" == "true" ]] && { [[ "$$NIGHTLY" == "1" ]] || git diff --name-only HEAD~1 | grep -qE '^(tpu_inference/kernels|tests/kernels|requirements(_.*)?\.txt)'; }; then
              .buildkite/scripts/run_in_docker.sh bash /workspace/tpu_inference/tests/e2e/check_lm_eval.sh  --model_name "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8" --use_moe_ep_kernel 0 --tensor_parallel_size 8 --max_model_len 2048 --max_num_batched_tokens 2048 --max_gen_toks 256 --enable_expert_parallel 1 --flex_threshold 0.85 --strict_threshold 0.70
            else
              echo "Skipping: Step requires TPU v7x and either a NIGHTLY build or kernel/requirements changes."
              exit 0
            fi

      - label: "${TPU_VERSION:-tpu6e} E2E lm_eval accuracy check gpt oss."
        key: ${TPU_VERSION:-tpu6e}_test_19
        soft_fail: true
        env:
          IS_FOR_V7X: "${IS_FOR_V7X}"
        agents:
          queue: ${TPU_QUEUE_MULTI:-tpu_v6e_8_queue}
        commands:
          - |
            if [[ "$$IS_FOR_V7X" == "true" ]] && { [[ "$$NIGHTLY" == "1" ]] || git diff --name-only HEAD~1 | grep -qE '^(tpu_inference/kernels|tests/kernels|requirements(_.*)?\.txt)'; }; then
              .buildkite/scripts/run_in_docker.sh bash /workspace/tpu_inference/tests/e2e/check_lm_eval.sh  --model_name "openai/gpt-oss-120b" --use_moe_ep_kernel 1 --tensor_parallel_size 8 --max_model_len 2048 --max_num_batched_tokens 2048 --max_gen_toks 256 --enable_expert_parallel 1 --flex_threshold 0.50 --strict_threshold 0.25
            else
              echo "Skipping: Step requires TPU v7x and either a NIGHTLY build or kernel/requirements changes."
              exit 0
            fi

      - label: "${TPU_VERSION:-tpu6e} Perf regression test for qwen3 coder 1k 8k."
        key: ${TPU_VERSION:-tpu6e}_test_20
        soft_fail: true
        env:
          IS_FOR_V7X: "${IS_FOR_V7X}"
        agents:
          queue: ${TPU_QUEUE_MULTI:-tpu_v6e_8_queue}
        if: build.env("NIGHTLY") == "1"
        commands:
          - |
            if [[ "$$IS_FOR_V7X" == "true" ]]; then
              .buildkite/scripts/run_in_docker.sh bash /workspace/tpu_inference/tests/e2e/benchmarking/bm_qwen3_coder.sh --model Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8 --tp 8 --req_tput_limit 0.15  --output_token_tput_limit 1170 --total_token_tput_limit 1314 --input_len 1024 --output_len 8192 --use_moe_ep_kernel 1
            fi
  
      - label: "${TPU_VERSION:-tpu6e} Perf regression test for qwen3 coder 8k 1k."
        key: ${TPU_VERSION:-tpu6e}_test_21
        soft_fail: true
        env:
          IS_FOR_V7X: "${IS_FOR_V7X}"
        agents:
          queue: ${TPU_QUEUE_MULTI:-tpu_v6e_8_queue}
        if: build.env("NIGHTLY") == "1"
        commands:
          - |
            if [[ "$$IS_FOR_V7X" == "true" ]]; then
              .buildkite/scripts/run_in_docker.sh bash /workspace/tpu_inference/tests/e2e/benchmarking/bm_qwen3_coder.sh --model Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8 --tp 8 --req_tput_limit 0.4  --output_token_tput_limit 381 --total_token_tput_limit 3421 --input_len 8192 --output_len 1024 --use_moe_ep_kernel 1
            fi
  
      - label: "${TPU_VERSION:-tpu6e} Perf regression test for qwen3 coder 1k 8k."
        key: ${TPU_VERSION:-tpu6e}_test_22
        soft_fail: true
        env:
          IS_FOR_V7X: "${IS_FOR_V7X}"
        agents:
          queue: ${TPU_QUEUE_MULTI:-tpu_v6e_8_queue}
        if: build.env("NIGHTLY") == "1"
        commands:
          - |
            if [[ "$$IS_FOR_V7X" == "true" ]]; then
              .buildkite/scripts/run_in_docker.sh bash /workspace/tpu_inference/tests/e2e/benchmarking/bm_qwen3_coder.sh --model Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8 --tp 8 --req_tput_limit 0.16  --output_token_tput_limit 1226 --total_token_tput_limit 1378 --input_len 1024 --output_len 8192 --use_moe_ep_kernel 0
            fi
  
      - label: "${TPU_VERSION:-tpu6e} Perf regression test for qwen3 coder 8k 1k."
        key: ${TPU_VERSION:-tpu6e}_test_23
        soft_fail: true
        env:
          IS_FOR_V7X: "${IS_FOR_V7X}"
        agents:
          queue: ${TPU_QUEUE_MULTI:-tpu_v6e_8_queue}
        if: build.env("NIGHTLY") == "1"
        commands:
          - |
            if [[ "$$IS_FOR_V7X" == "true" ]]; then
              .buildkite/scripts/run_in_docker.sh bash /workspace/tpu_inference/tests/e2e/benchmarking/bm_qwen3_coder.sh --model Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8 --tp 8 --req_tput_limit 0.63  --output_token_tput_limit 579 --total_token_tput_limit 5193 --input_len 8192 --output_len 1024 --use_moe_ep_kernel 0
            fi

      - label: "${TPU_VERSION:-tpu6e} Test EP recompilation."
        key: ${TPU_VERSION:-tpu6e}_test_24
        soft_fail: true
        env:
          IS_FOR_V7X: "${IS_FOR_V7X}"
        agents:
          queue: ${TPU_QUEUE_MULTI:-tpu_v6e_8_queue}
        commands:
          - |
            if [[ "$$IS_FOR_V7X" == "true" ]]; then
              .buildkite/scripts/run_in_docker.sh bash -c 'SKIP_JAX_PRECOMPILE=0 USE_MOE_EP_KERNEL=1 VLLM_XLA_CHECK_RECOMPILATION=1  MODEL_IMPL_TYPE=vllm python examples/offline_inference.py --model Qwen/Qwen1.5-MoE-A2.7B  --tensor-parallel-size 4 --enable-expert-parallel --no-async-scheduling --max-model-len 32 --max-num-batched-tokens 32 --max-num-seqs 8'
            fi
  
  # -----------------------------------------------------------------
  # NOTIFICATION STEP
  # -----------------------------------------------------------------
      - label: "${LABEL_PREFIX}TPU Test Notification"
        key: ${KEY_PREFIX}tpu_test_notification
        depends_on:
          - ${KEY_PREFIX}test_0
          - ${KEY_PREFIX}test_1
          - ${KEY_PREFIX}test_2
          - ${KEY_PREFIX}test_3
          - ${KEY_PREFIX}test_4
          - ${KEY_PREFIX}test_6
          - ${KEY_PREFIX}test_7_1
          - ${KEY_PREFIX}test_7_2
          - ${KEY_PREFIX}test_7_3
          - ${KEY_PREFIX}test_8
          - ${KEY_PREFIX}test_9
          - ${KEY_PREFIX}test_10
          - ${KEY_PREFIX}test_11
          - ${KEY_PREFIX}test_12
          - ${KEY_PREFIX}test_13
          - ${KEY_PREFIX}test_15
          - ${KEY_PREFIX}test_16
          - ${KEY_PREFIX}test_17
          - ${KEY_PREFIX}test_18
          - ${KEY_PREFIX}test_19
          - ${KEY_PREFIX}test_20
          - ${KEY_PREFIX}test_21
          - ${KEY_PREFIX}test_24
          agents:
            queue: cpu
          commands:
            - |
             .buildkite/scripts/check_results.sh \
               "TPU JAX Tests Failed" ${KEY_PREFIX}test_0 ${KEY_PREFIX}test_1 ${KEY_PREFIX}test_2 ${KEY_PREFIX}test_3 ${KEY_PREFIX}test_4 ${KEY_PREFIX}test_6 ${KEY_PREFIX}test_7_1 ${KEY_PREFIX}test_7_2 ${KEY_PREFIX}test_7_3 ${KEY_PREFIX}test_8 ${KEY_PREFIX}test_9 ${KEY_PREFIX}test_10 ${KEY_PREFIX}test_11 ${KEY_PREFIX}test_12 ${KEY_PREFIX}test_13 ${KEY_PREFIX}test_15 ${KEY_PREFIX}test_16 ${KEY_PREFIX}test_17 ${KEY_PREFIX}test_18 ${KEY_PREFIX}test_19 ${KEY_PREFIX}test_20 ${KEY_PREFIX}test_21 ${KEY_PREFIX}test_22 ${KEY_PREFIX}test_23 ${KEY_PREFIX}test_24
