# Copyright 2026 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

steps:
   - label: "PyPI Test Performance benchmarks for meta-llama/Llama-3.1-8B-Instruct"
     key: "pypi_meta-llama_Llama-3_1-8B-Instruct_Benchmark"
     if: build.env("NIGHTLY") == "1"
     agents:
      queue: tpu_v6e_queue
     env:
      TEST_MODEL: meta-llama/Llama-3.1-8B-Instruct
      TENSOR_PARALLEL_SIZE: 1
      MINIMUM_THROUGHPUT_THRESHOLD: 10.77
      INPUT_LEN: 1800
      OUTPUT_LEN: 128
      PREFIX_LEN: 0
      MAX_MODEL_LEN: 2048
      MAX_NUM_SEQS: 256
      MAX_NUM_BATCHED_TOKENS: 1024
     commands:
      - |
        .buildkite/scripts/run_with_pypi.sh bash /workspace/tpu_inference/tests/e2e/benchmarking/benchmark.sh

   - label: "PyPI Test Performance benchmarks for Qwen/Qwen3-4B"
     key: "pypi_Qwen_Qwen3-4B_Benchmark"
     if: build.env("NIGHTLY") == "1"
     agents:
      queue: tpu_v6e_queue
     env:
      TEST_MODEL: Qwen/Qwen3-4B
      TENSOR_PARALLEL_SIZE: 1
      MINIMUM_THROUGHPUT_THRESHOLD: 11.00
      INPUT_LEN: 1800
      OUTPUT_LEN: 128
      PREFIX_LEN: 0
      MAX_MODEL_LEN: 2048
      MAX_NUM_SEQS: 94
      MAX_NUM_BATCHED_TOKENS: 4096
     commands:
      - |
       .buildkite/scripts/run_with_pypi.sh bash /workspace/tpu_inference/tests/e2e/benchmarking/benchmark.sh
