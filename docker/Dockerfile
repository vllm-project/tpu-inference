ARG NIGHTLY_DATE="20250714"
ARG BASE_IMAGE="us-central1-docker.pkg.dev/tpu-pytorch-releases/docker/xla:nightly_3.12_tpuvm_$NIGHTLY_DATE"

FROM $BASE_IMAGE

ARG IS_FOR_V7X="false"

# Remove existing versions of dependencies
RUN pip uninstall -y torch torch_xla torchvision

# Install some basic utilities
RUN apt-get update && apt-get install -y \
    git \
    libopenblas-base libopenmpi-dev libomp-dev

# Build vLLM
WORKDIR /workspace/vllm
ARG VLLM_REPO=https://github.com/vllm-project/vllm.git
RUN git clone $VLLM_REPO /workspace/vllm
RUN pip install -r requirements/tpu.txt
RUN VLLM_TARGET_DEVICE="tpu" pip install -e .

# Install test dependencies
RUN python3 -m pip install -e tests/vllm_test_utils
RUN python3 -m pip install --no-cache-dir \
    git+https://github.com/thuml/depyf.git \
    pytest-asyncio \
    git+https://github.com/EleutherAI/lm-evaluation-harness.git@206b7722158f58c35b7ffcd53b035fdbdda5126d#egg=lm-eval[api] \
    pytest-cov \
    tblib \

# Install tpu_inference
WORKDIR /workspace/tpu_inference
# Install requirements first and cache so we don't need to re-install on code change.
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY requirements_benchmarking.txt .
# These are needed for the E2E benchmarking tests (i.e. tests/e2e/benchmarking/mlperf.sh)
RUN pip install -r requirements_benchmarking.txt
COPY . .
RUN pip install -e .

# TODO (jacobplatin): remove when v7x is supported in JAX/Libtpu officially
# NOTE: it's important that this is done after installing tpu_inference above,
# so that the v7x-specific dependencies can override any existing ones.
COPY requirements_v7x.txt .
RUN if [ "$IS_FOR_V7X" = "true" ]; then \
        pip install -r requirements_v7x.txt; \
    fi

CMD ["/bin/bash"]
