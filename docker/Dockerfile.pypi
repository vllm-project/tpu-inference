# ==============================================================================
# Dockerfile.pypi Purpose:
# This Dockerfile is used for building and testing vLLM-TPU as a distributable 
# Python package. 
#
# Key differences from the standard Dockerfile:
# 1. It builds a redistributable wheel (.whl) for vllm-tpu.
# 2. It installs the 'tpu-inference' package from a package index.
# 3. Use this file if you are verifying the PyPI distribution flow or need 
#    a production-ready wheel installation rather than an editable source build.
# ==============================================================================

ARG BASE_IMAGE="python:3.12-slim-bookworm"
# The latest main will be used if arg unspecified
ARG VLLM_COMMIT_HASH=""

FROM $BASE_IMAGE

ARG IS_FOR_V7X="false"
ARG IS_TEST="false"

# Install some basic utilities
RUN apt-get update && apt-get install -y \
    git \
    libopenmpi-dev \
    libomp-dev \
    procps \
    curl \
    rclone \
    wget \
    ca-certificates \
    && rm -rf /var/lib/apt/lists/*

# Install tpu_inference
WORKDIR /workspace/tpu_inference
COPY requirements.txt .
RUN --mount=type=cache,target=/root/.cache/pip pip install --extra-index-url https://download.pytorch.org/whl/cpu -r requirements.txt --retries 3
COPY requirements_benchmarking.txt .
# These are needed for the E2E benchmarking tests (i.e. tests/e2e/benchmarking/mlperf.sh)
RUN --mount=type=cache,target=/root/.cache/pip pip install -r requirements_benchmarking.txt --retries 3
# Install test requirements
COPY requirements_test.txt .
RUN  --mount=type=cache,target=/root/.cache/pip if [ "$IS_TEST" = "true" ]; then \
        pip install -r requirements_test.txt --retries 3; \
    fi
# TODO (jacobplatin): remove when v7x is supported in JAX/Libtpu officially
COPY requirements_v7x.txt .
RUN --mount=type=cache,target=/root/.cache/pip if [ "$IS_FOR_V7X" = "true" ]; then \
        pip install -r requirements_v7x.txt; \
    fi
COPY . .
# Build tpu_inference
RUN python3 -m pip install build
RUN TPU_INFERENCE_VERSION=$(date -u +%Y%m%d) && \
    echo $TPU_INFERENCE_VERSION > /tmp/version.txt && \
    VLLM_VERSION_OVERRIDE=${TPU_INFERENCE_VERSION} python3 -m build

# Build vllm-tpu wheel
WORKDIR /workspace
ARG VLLM_COMMIT_HASH
RUN TPU_INFERENCE_VERSION=$(cat /tmp/version.txt) && VLLM_TPU_VERSION=${TPU_INFERENCE_VERSION} && \
    bash tpu_inference/.buildkite/scripts/build_vllm_tpu.sh --local "${TPU_INFERENCE_VERSION}" "${VLLM_TPU_VERSION}" "${VLLM_COMMIT_HASH}"

# Install vllm-tpu wheel
RUN pip install --no-cache-dir vllm/dist/*.whl


CMD ["/bin/bash"]
