# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

name: âš¡ Discussion on the performance of TPU Inference
description: Submit a proposal/discussion about the performance of TPU Inference
title: "[Performance]: "
labels: ["performance"]

body:
- type: markdown
  attributes:
    value: >
      #### Before submitting an issue, please make sure the issue hasn't been already addressed by searching through [the existing and past issues](https://github.com/vllm-project/tpu-inference/issues?q=is%3Aissue+sort%3Acreated-desc+).
- type: textarea
  attributes:
    label: Proposal to improve performance
    description: >
      How do you plan to improve TPU Inference's performance?
  validations:
    required: false
- type: textarea
  attributes:
    label: Report of performance regression
    description: >
      Please provide detailed description of performance comparison to confirm the regression. You may want to run the benchmark script at https://github.com/vllm-project/vllm/tree/main/benchmarks .
  validations:
    required: false
- type: textarea
  attributes:
    label: Misc discussion on performance
    description: >
      Anything about the performance.
  validations:
    required: false
- type: textarea
  attributes:
    label: Your current environment (if you think it is necessary)
    description: |
      Please run the following and paste the output below.
      ```sh
      wget https://raw.githubusercontent.com/vllm-project/vllm/main/vllm/collect_env.py
      # For security purposes, please feel free to check the contents of collect_env.py before running it.
      python collect_env.py
      python -c "import jax; jax.print_environment_info()"
      ```
      It is suggested to download and execute the latest script, as vllm might frequently update the diagnosis information needed for accurately and quickly responding to issues.
    value: |
      ```text
      The output of commands above
      ```
  validations:
    required: false
- type: markdown
  attributes:
    value: >
      Thanks for contributing ðŸŽ‰!
- type: checkboxes
  id: askllm
  attributes:
    label: Before submitting a new issue...
    options:
      - label: Make sure you already searched for relevant issues and checked the [documentation page](https://github.com/vllm-project/tpu-inference/tree/main/docs), which can answer lots of frequently asked questions.
        required: true
