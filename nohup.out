WARNING:root:Defaulting to PJRT_DEVICE=CPU
INFO 10-28 17:06:30 [__init__.py:22] TPU info: node_name=sierraq-tpu7x-8 | tpu_type=tpu7x-8 | worker_id=0 | num_chips=8 | num_cores_per_chip=2
INFO 10-28 17:06:30 [importing.py:44] Triton is installed but 0 active driver(s) found (expected 1). Disabling Triton to prevent runtime errors.
INFO 10-28 17:06:30 [importing.py:68] Triton not installed or not compatible; certain GPU-related functions will not be available.
WARNING 10-28 17:06:30 [interface.py:171] Failed to import from vllm._C: ModuleNotFoundError("No module named 'vllm._C'")
WARNING 10-28 17:06:32 [argparse_utils.py:203] With `vllm serve`, you should provide the model as a positional argument or in a config file instead of via the `--model` option. The `--model` option will be removed in v0.13.
[1;36m(APIServer pid=1246691)[0;0m INFO 10-28 17:06:32 [api_server.py:1870] vLLM API server version 0.11.0rc2.dev373+g29255cfc3
[1;36m(APIServer pid=1246691)[0;0m INFO 10-28 17:06:32 [utils.py:253] non-default args: {'model_tag': 'deepseek-ai/DeepSeek-R1-0528', 'model': 'deepseek-ai/DeepSeek-R1-0528', 'hf_config_path': 'deepseek-ai/DeepSeek-R1-0528', 'max_model_len': 512, 'hf_overrides': {'architectures': ['DeepSeekV3']}, 'tensor_parallel_size': 8, 'gpu_memory_utilization': 0.2, 'max_num_batched_tokens': 512, 'max_num_seqs': 2, 'additional_config': {'quantization': 'fp8_deepseek.yaml', 'is_verbose': True}}
[1;36m(APIServer pid=1246691)[0;0m INFO 10-28 17:06:32 [config.py:413] Replacing legacy 'type' key with 'rope_type'
[1;36m(APIServer pid=1246691)[0;0m A new version of the following files was downloaded from https://huggingface.co/deepseek-ai/DeepSeek-R1-0528:
[1;36m(APIServer pid=1246691)[0;0m - configuration_deepseek.py
[1;36m(APIServer pid=1246691)[0;0m . Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.
[1;36m(APIServer pid=1246691)[0;0m A new version of the following files was downloaded from https://huggingface.co/deepseek-ai/DeepSeek-R1-0528:
[1;36m(APIServer pid=1246691)[0;0m - modeling_deepseek.py
[1;36m(APIServer pid=1246691)[0;0m . Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.
[1;36m(APIServer pid=1246691)[0;0m Traceback (most recent call last):
[1;36m(APIServer pid=1246691)[0;0m   File "/home/sierraq_google_com/anaconda3/envs/ullm/bin/vllm", line 7, in <module>
[1;36m(APIServer pid=1246691)[0;0m     sys.exit(main())
[1;36m(APIServer pid=1246691)[0;0m              ^^^^^^
[1;36m(APIServer pid=1246691)[0;0m   File "/home/sierraq_google_com/vllm/vllm/entrypoints/cli/main.py", line 73, in main
[1;36m(APIServer pid=1246691)[0;0m     args.dispatch_function(args)
[1;36m(APIServer pid=1246691)[0;0m   File "/home/sierraq_google_com/vllm/vllm/entrypoints/cli/serve.py", line 59, in cmd
[1;36m(APIServer pid=1246691)[0;0m     uvloop.run(run_server(args))
[1;36m(APIServer pid=1246691)[0;0m   File "/home/sierraq_google_com/anaconda3/envs/ullm/lib/python3.12/site-packages/uvloop/__init__.py", line 109, in run
[1;36m(APIServer pid=1246691)[0;0m     return __asyncio.run(
[1;36m(APIServer pid=1246691)[0;0m            ^^^^^^^^^^^^^^
[1;36m(APIServer pid=1246691)[0;0m   File "/home/sierraq_google_com/anaconda3/envs/ullm/lib/python3.12/asyncio/runners.py", line 195, in run
[1;36m(APIServer pid=1246691)[0;0m     return runner.run(main)
[1;36m(APIServer pid=1246691)[0;0m            ^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=1246691)[0;0m   File "/home/sierraq_google_com/anaconda3/envs/ullm/lib/python3.12/asyncio/runners.py", line 118, in run
[1;36m(APIServer pid=1246691)[0;0m     return self._loop.run_until_complete(task)
[1;36m(APIServer pid=1246691)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=1246691)[0;0m   File "uvloop/loop.pyx", line 1518, in uvloop.loop.Loop.run_until_complete
[1;36m(APIServer pid=1246691)[0;0m   File "/home/sierraq_google_com/anaconda3/envs/ullm/lib/python3.12/site-packages/uvloop/__init__.py", line 61, in wrapper
[1;36m(APIServer pid=1246691)[0;0m     return await main
[1;36m(APIServer pid=1246691)[0;0m            ^^^^^^^^^^
[1;36m(APIServer pid=1246691)[0;0m   File "/home/sierraq_google_com/vllm/vllm/entrypoints/openai/api_server.py", line 1914, in run_server
[1;36m(APIServer pid=1246691)[0;0m     await run_server_worker(listen_address, sock, args, **uvicorn_kwargs)
[1;36m(APIServer pid=1246691)[0;0m   File "/home/sierraq_google_com/vllm/vllm/entrypoints/openai/api_server.py", line 1930, in run_server_worker
[1;36m(APIServer pid=1246691)[0;0m     async with build_async_engine_client(
[1;36m(APIServer pid=1246691)[0;0m                ^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=1246691)[0;0m   File "/home/sierraq_google_com/anaconda3/envs/ullm/lib/python3.12/contextlib.py", line 210, in __aenter__
[1;36m(APIServer pid=1246691)[0;0m     return await anext(self.gen)
[1;36m(APIServer pid=1246691)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=1246691)[0;0m   File "/home/sierraq_google_com/vllm/vllm/entrypoints/openai/api_server.py", line 185, in build_async_engine_client
[1;36m(APIServer pid=1246691)[0;0m     async with build_async_engine_client_from_engine_args(
[1;36m(APIServer pid=1246691)[0;0m                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=1246691)[0;0m   File "/home/sierraq_google_com/anaconda3/envs/ullm/lib/python3.12/contextlib.py", line 210, in __aenter__
[1;36m(APIServer pid=1246691)[0;0m     return await anext(self.gen)
[1;36m(APIServer pid=1246691)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=1246691)[0;0m   File "/home/sierraq_google_com/vllm/vllm/entrypoints/openai/api_server.py", line 211, in build_async_engine_client_from_engine_args
[1;36m(APIServer pid=1246691)[0;0m     vllm_config = engine_args.create_engine_config(usage_context=usage_context)
[1;36m(APIServer pid=1246691)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=1246691)[0;0m   File "/home/sierraq_google_com/vllm/vllm/engine/arg_utils.py", line 1304, in create_engine_config
[1;36m(APIServer pid=1246691)[0;0m     model_config = self.create_model_config()
[1;36m(APIServer pid=1246691)[0;0m                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=1246691)[0;0m   File "/home/sierraq_google_com/vllm/vllm/engine/arg_utils.py", line 1161, in create_model_config
[1;36m(APIServer pid=1246691)[0;0m     return ModelConfig(
[1;36m(APIServer pid=1246691)[0;0m            ^^^^^^^^^^^^
[1;36m(APIServer pid=1246691)[0;0m   File "/home/sierraq_google_com/anaconda3/envs/ullm/lib/python3.12/site-packages/pydantic/_internal/_dataclasses.py", line 121, in __init__
[1;36m(APIServer pid=1246691)[0;0m     s.__pydantic_validator__.validate_python(ArgsKwargs(args, kwargs), self_instance=s)
[1;36m(APIServer pid=1246691)[0;0m pydantic_core._pydantic_core.ValidationError: 1 validation error for ModelConfig
[1;36m(APIServer pid=1246691)[0;0m   Value error, Model architectures ['DeepSeekV3'] are not supported for now. Supported architectures: dict_keys(['ApertusForCausalLM', 'AquilaModel', 'AquilaForCausalLM', 'ArceeForCausalLM', 'ArcticForCausalLM', 'BaiChuanForCausalLM', 'BaichuanForCausalLM', 'BailingMoeForCausalLM', 'BailingMoeV2ForCausalLM', 'BambaForCausalLM', 'BloomForCausalLM', 'ChatGLMModel', 'ChatGLMForConditionalGeneration', 'CohereForCausalLM', 'Cohere2ForCausalLM', 'CwmForCausalLM', 'DbrxForCausalLM', 'DeciLMForCausalLM', 'DeepseekForCausalLM', 'DeepseekV2ForCausalLM', 'DeepseekV3ForCausalLM', 'DeepseekV32ForCausalLM', 'Dots1ForCausalLM', 'Ernie4_5ForCausalLM', 'Ernie4_5_MoeForCausalLM', 'ExaoneForCausalLM', 'Exaone4ForCausalLM', 'Fairseq2LlamaForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FalconH1ForCausalLM', 'FlexOlmoForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'Gemma3ForCausalLM', 'Gemma3nForCausalLM', 'Qwen3NextForCausalLM', 'GlmForCausalLM', 'Glm4ForCausalLM', 'Glm4MoeForCausalLM', 'GptOssForCausalLM', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTJForCausalLM', 'GPTNeoXForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'GraniteMoeHybridForCausalLM', 'GraniteMoeSharedForCausalLM', 'GritLM', 'Grok1ModelForCausalLM', 'HunYuanMoEV1ForCausalLM', 'HunYuanDenseV1ForCausalLM', 'HCXVisionForCausalLM', 'InternLMForCausalLM', 'InternLM2ForCausalLM', 'InternLM2VEForCausalLM', 'InternLM3ForCausalLM', 'JAISLMHeadModel', 'JambaForCausalLM', 'Lfm2ForCausalLM', 'Lfm2MoeForCausalLM', 'LlamaForCausalLM', 'Llama4ForCausalLM', 'LLaMAForCausalLM', 'LongcatFlashForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MiniCPMForCausalLM', 'MiniCPM3ForCausalLM', 'MiniMaxForCausalLM', 'MiniMaxText01ForCausalLM', 'MiniMaxM1ForCausalLM', 'MiniMaxM2ForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MptForCausalLM', 'MPTForCausalLM', 'MiMoForCausalLM', 'NemotronForCausalLM', 'NemotronHForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'Olmo3ForCausalLM', 'OlmoeForCausalLM', 'OPTForCausalLM', 'OrionForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'PhiMoEForCausalLM', 'Plamo2ForCausalLM', 'QWenLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'Qwen3ForCausalLM', 'Qwen3MoeForCausalLM', 'RWForCausalLM', 'SeedOssForCausalLM', 'Step3TextForCausalLM', 'StableLMEpochForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'SolarForCausalLM', 'TeleChat2ForCausalLM', 'TeleFLMForCausalLM', 'XverseForCausalLM', 'Zamba2ForCausalLM', 'BertModel', 'BertSpladeSparseEmbeddingModel', 'Gemma2Model', 'Gemma3TextModel', 'GPT2ForSequenceClassification', 'GteModel', 'GteNewModel', 'InternLM2ForRewardModel', 'JambaForSequenceClassification', 'LlamaModel', 'MistralModel', 'ModernBertModel', 'NomicBertModel', 'Qwen2Model', 'Qwen2ForRewardModel', 'Qwen2ForProcessRewardModel', 'RobertaForMaskedLM', 'RobertaModel', 'XLMRobertaModel', 'CLIPModel', 'LlavaNextForConditionalGeneration', 'Phi3VForCausalLM', 'Qwen2VLForConditionalGeneration', 'SiglipModel', 'PrithviGeoSpatialMAE', 'Terratorch', 'BertForSequenceClassification', 'BertForTokenClassification', 'GteNewForSequenceClassification', 'ModernBertForSequenceClassification', 'ModernBertForTokenClassification', 'RobertaForSequenceClassification', 'XLMRobertaForSequenceClassification', 'JinaVLForRanking', 'AriaForConditionalGeneration', 'AyaVisionForConditionalGeneration', 'BeeForConditionalGeneration', 'Blip2ForConditionalGeneration', 'ChameleonForConditionalGeneration', 'Cohere2VisionForConditionalGeneration', 'DeepseekVLV2ForCausalLM', 'DeepseekOCRForCausalLM', 'DotsOCRForCausalLM', 'Ernie4_5_VLMoeForConditionalGeneration', 'FuyuForCausalLM', 'Gemma3ForConditionalGeneration', 'Gemma3nForConditionalGeneration', 'GLM4VForCausalLM', 'Glm4vForConditionalGeneration', 'Glm4vMoeForConditionalGeneration', 'GraniteSpeechForConditionalGeneration', 'H2OVLChatModel', 'InternVLChatModel', 'NemotronH_Nano_VL_V2', 'InternS1ForConditionalGeneration', 'InternVLForConditionalGeneration', 'Idefics3ForConditionalGeneration', 'SmolVLMForConditionalGeneration', 'KeyeForConditionalGeneration', 'KeyeVL1_5ForConditionalGeneration', 'RForConditionalGeneration', 'KimiVLForConditionalGeneration', 'LightOnOCRForConditionalGeneration', 'Llama_Nemotron_Nano_VL', 'Llama4ForConditionalGeneration', 'LlavaForConditionalGeneration', 'LlavaNextVideoForConditionalGeneration', 'LlavaOnevisionForConditionalGeneration', 'MantisForConditionalGeneration', 'MiDashengLMModel', 'MiniMaxVL01ForConditionalGeneration', 'MiniCPMO', 'MiniCPMV', 'Mistral3ForConditionalGeneration', 'MolmoForCausalLM', 'NVLM_D', 'Ovis', 'Ovis2_5', 'PaliGemmaForConditionalGeneration', 'Phi4MMForCausalLM', 'Phi4MultimodalForCausalLM', 'PixtralForConditionalGeneration', 'QwenVLForConditionalGeneration', 'Qwen2_5_VLForConditionalGeneration', 'Qwen2AudioForConditionalGeneration', 'Qwen2_5OmniModel', 'Qwen2_5OmniForConditionalGeneration', 'Qwen3OmniMoeForConditionalGeneration', 'Qwen3VLForConditionalGeneration', 'Qwen3VLMoeForConditionalGeneration', 'SkyworkR1VChatModel', 'Step3VLForConditionalGeneration', 'TarsierForConditionalGeneration', 'Tarsier2ForConditionalGeneration', 'UltravoxModel', 'VoxtralForConditionalGeneration', 'WhisperForConditionalGeneration', 'MiMoMTPModel', 'EagleLlamaForCausalLM', 'EagleLlama4ForCausalLM', 'EagleMiniCPMForCausalLM', 'Eagle3LlamaForCausalLM', 'LlamaForCausalLMEagle3', 'Eagle3Qwen2_5vlForCausalLM', 'EagleDeepSeekMTPModel', 'DeepSeekMTPModel', 'ErnieMTPModel', 'LongCatFlashMTPModel', 'Glm4MoeMTPModel', 'MedusaModel', 'Qwen3NextMTP', 'SmolLM3ForCausalLM', 'Emu3ForConditionalGeneration', 'TransformersForCausalLM', 'TransformersMoEForCausalLM', 'TransformersMultiModalForCausalLM', 'TransformersMultiModalMoEForCausalLM', 'TransformersEmbeddingModel', 'TransformersMoEEmbeddingModel', 'TransformersMultiModalEmbeddingModel', 'TransformersForSequenceClassification', 'TransformersMoEForSequenceClassification', 'TransformersMultiModalForSequenceClassification']) [type=value_error, input_value=ArgsKwargs((), {'model': ...rocessor_plugin': None}), input_type=ArgsKwargs]
[1;36m(APIServer pid=1246691)[0;0m     For further information visit https://errors.pydantic.dev/2.12/v/value_error
WARNING:root:Defaulting to PJRT_DEVICE=CPU
INFO 10-28 17:09:16 [__init__.py:22] TPU info: node_name=sierraq-tpu7x-8 | tpu_type=tpu7x-8 | worker_id=0 | num_chips=8 | num_cores_per_chip=2
INFO 10-28 17:09:16 [importing.py:44] Triton is installed but 0 active driver(s) found (expected 1). Disabling Triton to prevent runtime errors.
INFO 10-28 17:09:16 [importing.py:68] Triton not installed or not compatible; certain GPU-related functions will not be available.
WARNING 10-28 17:09:16 [interface.py:171] Failed to import from vllm._C: ModuleNotFoundError("No module named 'vllm._C'")
WARNING 10-28 17:09:17 [argparse_utils.py:203] With `vllm serve`, you should provide the model as a positional argument or in a config file instead of via the `--model` option. The `--model` option will be removed in v0.13.
[1;36m(APIServer pid=1247004)[0;0m INFO 10-28 17:09:17 [api_server.py:1870] vLLM API server version 0.11.0rc2.dev373+g29255cfc3
[1;36m(APIServer pid=1247004)[0;0m INFO 10-28 17:09:17 [utils.py:253] non-default args: {'model_tag': 'deepseek-ai/DeepSeek-R1-0528', 'model': 'deepseek-ai/DeepSeek-R1-0528', 'hf_config_path': 'deepseek-ai/DeepSeek-R1-0528', 'max_model_len': 512, 'hf_overrides': {'architectures': ['DeepSeekV3']}, 'tensor_parallel_size': 8, 'gpu_memory_utilization': 0.2, 'max_num_batched_tokens': 512, 'max_num_seqs': 2}
[1;36m(APIServer pid=1247004)[0;0m INFO 10-28 17:09:17 [config.py:413] Replacing legacy 'type' key with 'rope_type'
[1;36m(APIServer pid=1247004)[0;0m Traceback (most recent call last):
[1;36m(APIServer pid=1247004)[0;0m   File "/home/sierraq_google_com/anaconda3/envs/ullm/bin/vllm", line 7, in <module>
[1;36m(APIServer pid=1247004)[0;0m     sys.exit(main())
[1;36m(APIServer pid=1247004)[0;0m              ^^^^^^
[1;36m(APIServer pid=1247004)[0;0m   File "/home/sierraq_google_com/vllm/vllm/entrypoints/cli/main.py", line 73, in main
[1;36m(APIServer pid=1247004)[0;0m     args.dispatch_function(args)
[1;36m(APIServer pid=1247004)[0;0m   File "/home/sierraq_google_com/vllm/vllm/entrypoints/cli/serve.py", line 59, in cmd
[1;36m(APIServer pid=1247004)[0;0m     uvloop.run(run_server(args))
[1;36m(APIServer pid=1247004)[0;0m   File "/home/sierraq_google_com/anaconda3/envs/ullm/lib/python3.12/site-packages/uvloop/__init__.py", line 109, in run
[1;36m(APIServer pid=1247004)[0;0m     return __asyncio.run(
[1;36m(APIServer pid=1247004)[0;0m            ^^^^^^^^^^^^^^
[1;36m(APIServer pid=1247004)[0;0m   File "/home/sierraq_google_com/anaconda3/envs/ullm/lib/python3.12/asyncio/runners.py", line 195, in run
[1;36m(APIServer pid=1247004)[0;0m     return runner.run(main)
[1;36m(APIServer pid=1247004)[0;0m            ^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=1247004)[0;0m   File "/home/sierraq_google_com/anaconda3/envs/ullm/lib/python3.12/asyncio/runners.py", line 118, in run
[1;36m(APIServer pid=1247004)[0;0m     return self._loop.run_until_complete(task)
[1;36m(APIServer pid=1247004)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=1247004)[0;0m   File "uvloop/loop.pyx", line 1518, in uvloop.loop.Loop.run_until_complete
[1;36m(APIServer pid=1247004)[0;0m   File "/home/sierraq_google_com/anaconda3/envs/ullm/lib/python3.12/site-packages/uvloop/__init__.py", line 61, in wrapper
[1;36m(APIServer pid=1247004)[0;0m     return await main
[1;36m(APIServer pid=1247004)[0;0m            ^^^^^^^^^^
[1;36m(APIServer pid=1247004)[0;0m   File "/home/sierraq_google_com/vllm/vllm/entrypoints/openai/api_server.py", line 1914, in run_server
[1;36m(APIServer pid=1247004)[0;0m     await run_server_worker(listen_address, sock, args, **uvicorn_kwargs)
[1;36m(APIServer pid=1247004)[0;0m   File "/home/sierraq_google_com/vllm/vllm/entrypoints/openai/api_server.py", line 1930, in run_server_worker
[1;36m(APIServer pid=1247004)[0;0m     async with build_async_engine_client(
[1;36m(APIServer pid=1247004)[0;0m                ^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=1247004)[0;0m   File "/home/sierraq_google_com/anaconda3/envs/ullm/lib/python3.12/contextlib.py", line 210, in __aenter__
[1;36m(APIServer pid=1247004)[0;0m     return await anext(self.gen)
[1;36m(APIServer pid=1247004)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=1247004)[0;0m   File "/home/sierraq_google_com/vllm/vllm/entrypoints/openai/api_server.py", line 185, in build_async_engine_client
[1;36m(APIServer pid=1247004)[0;0m     async with build_async_engine_client_from_engine_args(
[1;36m(APIServer pid=1247004)[0;0m                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=1247004)[0;0m   File "/home/sierraq_google_com/anaconda3/envs/ullm/lib/python3.12/contextlib.py", line 210, in __aenter__
[1;36m(APIServer pid=1247004)[0;0m     return await anext(self.gen)
[1;36m(APIServer pid=1247004)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=1247004)[0;0m   File "/home/sierraq_google_com/vllm/vllm/entrypoints/openai/api_server.py", line 211, in build_async_engine_client_from_engine_args
[1;36m(APIServer pid=1247004)[0;0m     vllm_config = engine_args.create_engine_config(usage_context=usage_context)
[1;36m(APIServer pid=1247004)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=1247004)[0;0m   File "/home/sierraq_google_com/vllm/vllm/engine/arg_utils.py", line 1304, in create_engine_config
[1;36m(APIServer pid=1247004)[0;0m     model_config = self.create_model_config()
[1;36m(APIServer pid=1247004)[0;0m                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=1247004)[0;0m   File "/home/sierraq_google_com/vllm/vllm/engine/arg_utils.py", line 1161, in create_model_config
[1;36m(APIServer pid=1247004)[0;0m     return ModelConfig(
[1;36m(APIServer pid=1247004)[0;0m            ^^^^^^^^^^^^
[1;36m(APIServer pid=1247004)[0;0m   File "/home/sierraq_google_com/anaconda3/envs/ullm/lib/python3.12/site-packages/pydantic/_internal/_dataclasses.py", line 121, in __init__
[1;36m(APIServer pid=1247004)[0;0m     s.__pydantic_validator__.validate_python(ArgsKwargs(args, kwargs), self_instance=s)
[1;36m(APIServer pid=1247004)[0;0m pydantic_core._pydantic_core.ValidationError: 1 validation error for ModelConfig
[1;36m(APIServer pid=1247004)[0;0m   Value error, Model architectures ['DeepSeekV3'] are not supported for now. Supported architectures: dict_keys(['ApertusForCausalLM', 'AquilaModel', 'AquilaForCausalLM', 'ArceeForCausalLM', 'ArcticForCausalLM', 'BaiChuanForCausalLM', 'BaichuanForCausalLM', 'BailingMoeForCausalLM', 'BailingMoeV2ForCausalLM', 'BambaForCausalLM', 'BloomForCausalLM', 'ChatGLMModel', 'ChatGLMForConditionalGeneration', 'CohereForCausalLM', 'Cohere2ForCausalLM', 'CwmForCausalLM', 'DbrxForCausalLM', 'DeciLMForCausalLM', 'DeepseekForCausalLM', 'DeepseekV2ForCausalLM', 'DeepseekV3ForCausalLM', 'DeepseekV32ForCausalLM', 'Dots1ForCausalLM', 'Ernie4_5ForCausalLM', 'Ernie4_5_MoeForCausalLM', 'ExaoneForCausalLM', 'Exaone4ForCausalLM', 'Fairseq2LlamaForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FalconH1ForCausalLM', 'FlexOlmoForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'Gemma3ForCausalLM', 'Gemma3nForCausalLM', 'Qwen3NextForCausalLM', 'GlmForCausalLM', 'Glm4ForCausalLM', 'Glm4MoeForCausalLM', 'GptOssForCausalLM', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTJForCausalLM', 'GPTNeoXForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'GraniteMoeHybridForCausalLM', 'GraniteMoeSharedForCausalLM', 'GritLM', 'Grok1ModelForCausalLM', 'HunYuanMoEV1ForCausalLM', 'HunYuanDenseV1ForCausalLM', 'HCXVisionForCausalLM', 'InternLMForCausalLM', 'InternLM2ForCausalLM', 'InternLM2VEForCausalLM', 'InternLM3ForCausalLM', 'JAISLMHeadModel', 'JambaForCausalLM', 'Lfm2ForCausalLM', 'Lfm2MoeForCausalLM', 'LlamaForCausalLM', 'Llama4ForCausalLM', 'LLaMAForCausalLM', 'LongcatFlashForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MiniCPMForCausalLM', 'MiniCPM3ForCausalLM', 'MiniMaxForCausalLM', 'MiniMaxText01ForCausalLM', 'MiniMaxM1ForCausalLM', 'MiniMaxM2ForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MptForCausalLM', 'MPTForCausalLM', 'MiMoForCausalLM', 'NemotronForCausalLM', 'NemotronHForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'Olmo3ForCausalLM', 'OlmoeForCausalLM', 'OPTForCausalLM', 'OrionForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'PhiMoEForCausalLM', 'Plamo2ForCausalLM', 'QWenLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'Qwen3ForCausalLM', 'Qwen3MoeForCausalLM', 'RWForCausalLM', 'SeedOssForCausalLM', 'Step3TextForCausalLM', 'StableLMEpochForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'SolarForCausalLM', 'TeleChat2ForCausalLM', 'TeleFLMForCausalLM', 'XverseForCausalLM', 'Zamba2ForCausalLM', 'BertModel', 'BertSpladeSparseEmbeddingModel', 'Gemma2Model', 'Gemma3TextModel', 'GPT2ForSequenceClassification', 'GteModel', 'GteNewModel', 'InternLM2ForRewardModel', 'JambaForSequenceClassification', 'LlamaModel', 'MistralModel', 'ModernBertModel', 'NomicBertModel', 'Qwen2Model', 'Qwen2ForRewardModel', 'Qwen2ForProcessRewardModel', 'RobertaForMaskedLM', 'RobertaModel', 'XLMRobertaModel', 'CLIPModel', 'LlavaNextForConditionalGeneration', 'Phi3VForCausalLM', 'Qwen2VLForConditionalGeneration', 'SiglipModel', 'PrithviGeoSpatialMAE', 'Terratorch', 'BertForSequenceClassification', 'BertForTokenClassification', 'GteNewForSequenceClassification', 'ModernBertForSequenceClassification', 'ModernBertForTokenClassification', 'RobertaForSequenceClassification', 'XLMRobertaForSequenceClassification', 'JinaVLForRanking', 'AriaForConditionalGeneration', 'AyaVisionForConditionalGeneration', 'BeeForConditionalGeneration', 'Blip2ForConditionalGeneration', 'ChameleonForConditionalGeneration', 'Cohere2VisionForConditionalGeneration', 'DeepseekVLV2ForCausalLM', 'DeepseekOCRForCausalLM', 'DotsOCRForCausalLM', 'Ernie4_5_VLMoeForConditionalGeneration', 'FuyuForCausalLM', 'Gemma3ForConditionalGeneration', 'Gemma3nForConditionalGeneration', 'GLM4VForCausalLM', 'Glm4vForConditionalGeneration', 'Glm4vMoeForConditionalGeneration', 'GraniteSpeechForConditionalGeneration', 'H2OVLChatModel', 'InternVLChatModel', 'NemotronH_Nano_VL_V2', 'InternS1ForConditionalGeneration', 'InternVLForConditionalGeneration', 'Idefics3ForConditionalGeneration', 'SmolVLMForConditionalGeneration', 'KeyeForConditionalGeneration', 'KeyeVL1_5ForConditionalGeneration', 'RForConditionalGeneration', 'KimiVLForConditionalGeneration', 'LightOnOCRForConditionalGeneration', 'Llama_Nemotron_Nano_VL', 'Llama4ForConditionalGeneration', 'LlavaForConditionalGeneration', 'LlavaNextVideoForConditionalGeneration', 'LlavaOnevisionForConditionalGeneration', 'MantisForConditionalGeneration', 'MiDashengLMModel', 'MiniMaxVL01ForConditionalGeneration', 'MiniCPMO', 'MiniCPMV', 'Mistral3ForConditionalGeneration', 'MolmoForCausalLM', 'NVLM_D', 'Ovis', 'Ovis2_5', 'PaliGemmaForConditionalGeneration', 'Phi4MMForCausalLM', 'Phi4MultimodalForCausalLM', 'PixtralForConditionalGeneration', 'QwenVLForConditionalGeneration', 'Qwen2_5_VLForConditionalGeneration', 'Qwen2AudioForConditionalGeneration', 'Qwen2_5OmniModel', 'Qwen2_5OmniForConditionalGeneration', 'Qwen3OmniMoeForConditionalGeneration', 'Qwen3VLForConditionalGeneration', 'Qwen3VLMoeForConditionalGeneration', 'SkyworkR1VChatModel', 'Step3VLForConditionalGeneration', 'TarsierForConditionalGeneration', 'Tarsier2ForConditionalGeneration', 'UltravoxModel', 'VoxtralForConditionalGeneration', 'WhisperForConditionalGeneration', 'MiMoMTPModel', 'EagleLlamaForCausalLM', 'EagleLlama4ForCausalLM', 'EagleMiniCPMForCausalLM', 'Eagle3LlamaForCausalLM', 'LlamaForCausalLMEagle3', 'Eagle3Qwen2_5vlForCausalLM', 'EagleDeepSeekMTPModel', 'DeepSeekMTPModel', 'ErnieMTPModel', 'LongCatFlashMTPModel', 'Glm4MoeMTPModel', 'MedusaModel', 'Qwen3NextMTP', 'SmolLM3ForCausalLM', 'Emu3ForConditionalGeneration', 'TransformersForCausalLM', 'TransformersMoEForCausalLM', 'TransformersMultiModalForCausalLM', 'TransformersMultiModalMoEForCausalLM', 'TransformersEmbeddingModel', 'TransformersMoEEmbeddingModel', 'TransformersMultiModalEmbeddingModel', 'TransformersForSequenceClassification', 'TransformersMoEForSequenceClassification', 'TransformersMultiModalForSequenceClassification']) [type=value_error, input_value=ArgsKwargs((), {'model': ...rocessor_plugin': None}), input_type=ArgsKwargs]
[1;36m(APIServer pid=1247004)[0;0m     For further information visit https://errors.pydantic.dev/2.12/v/value_error
